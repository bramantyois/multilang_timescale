{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ra/Codes/multilang_timescale\n"
     ]
    }
   ],
   "source": [
    "# move to project root\n",
    "while True:\n",
    "    # get list of directories\n",
    "    dirs = os.listdir()\n",
    "    if \"README.md\" in dirs:\n",
    "        break\n",
    "    else:\n",
    "        os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "DEBUG:matplotlib:matplotlib data path: /home/ra/miniconda3/envs/vem/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "DEBUG:matplotlib:CONFIGDIR=/home/ra/.config/matplotlib\n",
      "DEBUG:matplotlib:interactive is False\n",
      "DEBUG:matplotlib:platform is linux\n",
      "DEBUG:matplotlib:CACHEDIR=/home/ra/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/ra/.cache/matplotlib/fontlist-v330.json\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "#from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from himalaya.ridge import RidgeCV, Ridge\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "from matplotlib.pyplot import figure, cm\n",
    "\n",
    "from src.vm_tutorial_sklearn.stimulus_utils import (\n",
    "    load_grids_for_stories,\n",
    "    load_generic_trfiles,\n",
    "    load_story_info,\n",
    ")\n",
    "from src.vm_tutorial_sklearn.dsutils import make_word_ds, make_phoneme_ds\n",
    "from src.vm_tutorial_sklearn.util import make_delayed, load_dict\n",
    "from src.vm_tutorial_sklearn.hard_coded_things import (\n",
    "    test_stories,\n",
    "    train_stories,\n",
    "    silence_length,\n",
    "    noise_trim_length,\n",
    ")\n",
    "\n",
    "from src.config import (\n",
    "    grids_en_path,\n",
    "    trs_en_path,\n",
    "    feature_sets_en_path,\n",
    "    reading_data_en_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"07\"\n",
    "timescale = \"2_4_words\"\n",
    "\n",
    "# timescale = \"2_4_words\"\n",
    "# data_dir = os.path.join(reading_data_path, \"data_en\")\n",
    "# featureset_dir = os.path.join(reading_data_path, \"featureset_en\")\n",
    "# grid_dir = os.path.join(reading_data_path, \"grids_en\")\n",
    "# trf_dir = os.path.join(reading_data_path, \"trfiles_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Himalaya on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = set_backend(\"torch_cuda\", on_error=\"warn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding audio\n",
    "all_stories = train_stories + test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load story info\n",
    "story_info = load_story_info(\n",
    "    story_name=train_stories[0], grids_path=grids_en_path, trs_path=trs_en_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_feature_set = os.path.join(feature_sets_en_path, \"timescales_BERT_all.npz\")\n",
    "mbert_feature_set = os.path.join(feature_sets_en_path, \"timescales_mBERT_all.npz\")\n",
    "\n",
    "bert_features_meta = os.path.join(\n",
    "    feature_sets_en_path, \"timescales_BERT_all_train_meta.csv\"\n",
    ")\n",
    "mbert_features_meta = os.path.join(\n",
    "    feature_sets_en_path, \"timescales_mBERT_all_train_meta.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_features = np.load(bert_feature_set, allow_pickle=True)\n",
    "\n",
    "bert_train_feature = bert_features[\"train\"].tolist()\n",
    "bert_test_feature = bert_features[\"test\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_train_feature_fast = bert_train_feature[timescala]\n",
    "# bert_test_feature_fast = bert_test_feature[timescale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_meta = pd.read_csv(bert_features_meta, index_col=0)\n",
    "# bert_meta_fast = bert_meta[bert_meta[\"timescale_name\"] == timescale]\n",
    "\n",
    "# bert_meta_fast.sort_values(\"index\", inplace=True)\n",
    "# # now get rolling sum of feature_len\n",
    "# feature_end_idx = bert_meta_fast[\"feature_len\"].rolling(min_periods=1, window=10).sum()\n",
    "# feature_end_idx = feature_end_idx.astype(int)\n",
    "# feature_end_idx = feature_end_idx.tolist()\n",
    "\n",
    "# # zip with story_names\n",
    "# end_index = {a: b for a, b in zip(bert_meta_fast[\"story_name\"], feature_end_idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delaying Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2_4_words', '4_8_words', '8_16_words', '16_32_words', '32_64_words', '64_128_words', '128_256_words', '256+ words'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train_feature.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndelays = 4\n",
    "delays = np.arange(1, ndelays + 1)\n",
    "\n",
    "# delaying all features\n",
    "delayed_train_features = {}\n",
    "delayed_test_features = {}\n",
    "\n",
    "for story in bert_train_feature.keys():\n",
    "    delayed_train_features[story] = make_delayed(\n",
    "        bert_train_feature[story], delays=delays\n",
    "    )\n",
    "    delayed_test_features[story] = make_delayed(bert_test_feature[story], delays=delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndelays = 4\n",
    "# delays = np.arange(1, ndelays + 1)\n",
    "\n",
    "# del_training_stim = make_delayed(bert_train_feature_fast, delays)\n",
    "# del_test_stim = make_delayed(bert_test_feature_fast, delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = f\"subject{subject}_reading_fmri_data_trn.hdf\"\n",
    "test_fn = f\"subject{subject}_reading_fmri_data_val.hdf\"\n",
    "\n",
    "training_data = load_dict(os.path.join(reading_data_en_path, train_fn))\n",
    "test_data = load_dict(os.path.join(reading_data_en_path, test_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = 5\n",
    "ztraining_data = np.vstack(\n",
    "    [\n",
    "        zscore(\n",
    "            training_data[story][\n",
    "                silence_length + noise_trim_length : -(noise_trim_length+silence_length), :\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        for story in list(training_data.keys())\n",
    "    ]\n",
    ")\n",
    "ztest_data = zscore(\n",
    "    np.mean(test_data[\"story_11\"], axis=0)[silence_length + noise_trim_length : -(noise_trim_length+silence_length), :], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737, 92970)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztraining_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737, 39936)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delayed_train_features[timescale].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ztraining_data.shape[0] == delayed_train_features[timescale].shape[0]\n",
    "assert ztest_data.shape[0] == delayed_test_features[timescale].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data to backend\n",
    "X = np.nan_to_num(delayed_train_features[timescale]).astype(np.float32)\n",
    "Y = np.nan_to_num(ztraining_data).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ra/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/ridge/_random_search.py:491: UserWarning: Solving ridge is slower than solving kernel ridge when n_samples < n_features (here 3737 < 39936). Using a linear kernel in himalaya.kernel_ridge.KernelRidgeCV or himalaya.kernel_ridge.solve_kernel_ridge_cv_eigenvalues would be faster. Use warn=False to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m reg \u001b[38;5;241m=\u001b[39m RidgeCV(alphas\u001b[38;5;241m=\u001b[39malphas, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,) \n\u001b[0;32m----> 7\u001b[0m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/backend/_utils.py:97\u001b[0m, in \u001b[0;36mforce_cpu_backend.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# skip if the object does not force cpu use\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_cpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mforce_cpu:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# set corresponding cpu backend\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     original_backend \u001b[38;5;241m=\u001b[39m get_backend()\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/ridge/_sklearn_api.py:321\u001b[0m, in \u001b[0;36mRidgeCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    318\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# ------------------ call the solver\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mY_in_cpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mY_in_cpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_alphas_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_scores_ \u001b[38;5;241m=\u001b[39m tmp[:\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/ridge/_sklearn_api.py:44\u001b[0m, in \u001b[0;36m_BaseRidge._call_solver\u001b[0;34m(self, **direct_params)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m intersection:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameters \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m should not be given in solver_params, since \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthey are either fixed or have a direct parameter in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m     42\u001b[0m         (intersection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdirect_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msolver_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/ridge/_random_search.py:510\u001b[0m, in \u001b[0;36msolve_ridge_cv_svd\u001b[0;34m(X, Y, alphas, fit_intercept, score_func, cv, local_alpha, n_targets_batch, n_targets_batch_refit, n_alphas_batch, conservative, Y_in_cpu, warn)\u001b[0m\n\u001b[1;32m    499\u001b[0m fixed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(return_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    500\u001b[0m                     concentration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, jitter_alphas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    501\u001b[0m                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_iter\u001b[38;5;241m=\u001b[39mn_iter, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    503\u001b[0m copied_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(alphas\u001b[38;5;241m=\u001b[39malphas, score_func\u001b[38;5;241m=\u001b[39mscore_func, cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    504\u001b[0m                      local_alpha\u001b[38;5;241m=\u001b[39mlocal_alpha, fit_intercept\u001b[38;5;241m=\u001b[39mfit_intercept,\n\u001b[1;32m    505\u001b[0m                      n_targets_batch\u001b[38;5;241m=\u001b[39mn_targets_batch,\n\u001b[1;32m    506\u001b[0m                      n_targets_batch_refit\u001b[38;5;241m=\u001b[39mn_targets_batch_refit,\n\u001b[1;32m    507\u001b[0m                      n_alphas_batch\u001b[38;5;241m=\u001b[39mn_alphas_batch,\n\u001b[1;32m    508\u001b[0m                      conservative\u001b[38;5;241m=\u001b[39mconservative, Y_in_cpu\u001b[38;5;241m=\u001b[39mY_in_cpu)\n\u001b[0;32m--> 510\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43msolve_group_ridge_random_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfixed_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_intercept:\n\u001b[1;32m    514\u001b[0m     deltas, coefs, cv_scores, intercept \u001b[38;5;241m=\u001b[39m tmp\n",
      "File \u001b[0;32m~/miniconda3/envs/vem/lib/python3.11/site-packages/himalaya/ridge/_random_search.py:221\u001b[0m, in \u001b[0;36msolve_group_ridge_random_search\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    214\u001b[0m     Xtest \u001b[38;5;241m=\u001b[39m X_[test] \u001b[38;5;241m-\u001b[39m Xtrain_mean\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m matrix, alpha_batch \u001b[38;5;129;01min\u001b[39;00m _decompose_ridge(\n\u001b[1;32m    217\u001b[0m         Xtrain\u001b[38;5;241m=\u001b[39mXtrain, alphas\u001b[38;5;241m=\u001b[39malphas, negative_eigenvalues\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m         n_alphas_batch\u001b[38;5;241m=\u001b[39mn_alphas_batch, method\u001b[38;5;241m=\u001b[39mdiagonalize_method):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# n_alphas_batch, n_features, n_samples_train = \\\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# matrix.shape\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# n_alphas_batch, n_samples_test, n_samples_train = \\\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# matrix.shape\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(1, 3, 10)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "reg = RidgeCV(alphas=alphas, cv=5,) \n",
    "\n",
    "reg.fit(X, Y)\n",
    "\n",
    "print(f\"Training took {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
