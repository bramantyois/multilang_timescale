{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ra/Codes/multilang_timescale\n"
     ]
    }
   ],
   "source": [
    "# move to project root\n",
    "while True:\n",
    "    # get list of directories\n",
    "    dirs = os.listdir()\n",
    "    if \"README.md\" in dirs:\n",
    "        break\n",
    "    else:\n",
    "        os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from matplotlib.pyplot import figure, cm\n",
    "\n",
    "from src.vm_tutorial_sklearn.stimulus_utils import (\n",
    "    load_grids_for_stories,\n",
    "    load_generic_trfiles,\n",
    "    load_story_info,\n",
    ")\n",
    "from src.vm_tutorial_sklearn.dsutils import make_word_ds, make_phoneme_ds\n",
    "from src.vm_tutorial_sklearn.util import make_delayed, load_dict\n",
    "from src.vm_tutorial_sklearn.hard_coded_things import (\n",
    "    test_stories,\n",
    "    train_stories,\n",
    "    silence_length,\n",
    "    noise_trim_length,\n",
    ")\n",
    "\n",
    "from src.config import (\n",
    "    grids_en_path,\n",
    "    trs_en_path,\n",
    "    feature_sets_en_path,\n",
    "    reading_data_en_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"07\"\n",
    "timescale = \"2_4_words\"\n",
    "\n",
    "# timescale = \"2_4_words\"\n",
    "# data_dir = os.path.join(reading_data_path, \"data_en\")\n",
    "# featureset_dir = os.path.join(reading_data_path, \"featureset_en\")\n",
    "# grid_dir = os.path.join(reading_data_path, \"grids_en\")\n",
    "# trf_dir = os.path.join(reading_data_path, \"trfiles_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding audio\n",
    "all_stories = train_stories + test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load story info\n",
    "story_info = load_story_info(\n",
    "    story_name=train_stories[0], grids_path=grids_en_path, trs_path=trs_en_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_feature_set = os.path.join(feature_sets_en_path, \"timescales_BERT_all.npz\")\n",
    "mbert_feature_set = os.path.join(feature_sets_en_path, \"timescales_mBERT_all.npz\")\n",
    "\n",
    "bert_features_meta = os.path.join(\n",
    "    feature_sets_en_path, \"timescales_BERT_all_train_meta.csv\"\n",
    ")\n",
    "mbert_features_meta = os.path.join(\n",
    "    feature_sets_en_path, \"timescales_mBERT_all_train_meta.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_features = np.load(bert_feature_set, allow_pickle=True)\n",
    "\n",
    "bert_train_feature = bert_features[\"train\"].tolist()\n",
    "bert_test_feature = bert_features[\"test\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_train_feature_fast = bert_train_feature[timescala]\n",
    "# bert_test_feature_fast = bert_test_feature[timescale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_meta = pd.read_csv(bert_features_meta, index_col=0)\n",
    "# bert_meta_fast = bert_meta[bert_meta[\"timescale_name\"] == timescale]\n",
    "\n",
    "# bert_meta_fast.sort_values(\"index\", inplace=True)\n",
    "# # now get rolling sum of feature_len\n",
    "# feature_end_idx = bert_meta_fast[\"feature_len\"].rolling(min_periods=1, window=10).sum()\n",
    "# feature_end_idx = feature_end_idx.astype(int)\n",
    "# feature_end_idx = feature_end_idx.tolist()\n",
    "\n",
    "# # zip with story_names\n",
    "# end_index = {a: b for a, b in zip(bert_meta_fast[\"story_name\"], feature_end_idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delaying Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2_4_words', '4_8_words', '8_16_words', '16_32_words', '32_64_words', '64_128_words', '128_256_words', '256+ words'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train_feature.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndelays = 4\n",
    "delays = np.arange(1, ndelays + 1)\n",
    "\n",
    "# delaying all features\n",
    "delayed_train_features = {}\n",
    "delayed_test_features = {}\n",
    "\n",
    "for story in bert_train_feature.keys():\n",
    "    delayed_train_features[story] = make_delayed(\n",
    "        bert_train_feature[story], delays=delays\n",
    "    )\n",
    "    delayed_test_features[story] = make_delayed(bert_test_feature[story], delays=delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndelays = 4\n",
    "# delays = np.arange(1, ndelays + 1)\n",
    "\n",
    "# del_training_stim = make_delayed(bert_train_feature_fast, delays)\n",
    "# del_test_stim = make_delayed(bert_test_feature_fast, delays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = f\"subject{subject}_reading_fmri_data_trn.hdf\"\n",
    "test_fn = f\"subject{subject}_reading_fmri_data_val.hdf\"\n",
    "\n",
    "training_data = load_dict(os.path.join(reading_data_en_path, train_fn))\n",
    "test_data = load_dict(os.path.join(reading_data_en_path, test_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = 5\n",
    "ztraining_data = np.vstack(\n",
    "    [\n",
    "        zscore(\n",
    "            training_data[story][\n",
    "                silence_length + noise_trim_length : -(noise_trim_length+silence_length), :\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        for story in list(training_data.keys())\n",
    "    ]\n",
    ")\n",
    "ztest_data = zscore(\n",
    "    np.mean(test_data[\"story_11\"], axis=0)[silence_length + noise_trim_length : -(noise_trim_length+silence_length), :], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737, 92970)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztraining_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737, 39936)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delayed_train_features[timescale].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ztraining_data.shape[0] == delayed_train_features[timescale].shape[0]\n",
    "assert ztest_data.shape[0] == delayed_test_features[timescale].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "alphas = np.logspace(1, 3, 10)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "reg = RidgeCV(alphas=alphas, cv=kfold.split(ztraining_data), store_cv_values=False)\n",
    "\n",
    "reg.fit(np.nan_to_num(delayed_train_features[timescale]), np.nan_to_num(ztraining_data))\n",
    "\n",
    "print(f\"Training took {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
